{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Constructor\n",
    "        '''\n",
    "        self.wordEmbeddingDimension = 70\n",
    "        self.vocabularySize=665000\n",
    "        self.labels=5000\n",
    "        self.filterSizes_paragraph = [3]\n",
    "        self.filterSizes_allPara=3\n",
    "        self.paragraphLength=100\n",
    "        self.num_filters_parargaph=15\n",
    "        self.num_filters_allPara=20\n",
    "        self.maxParagraph = 7\n",
    "\n",
    "        self.filterShapeOfAllPara =[self.filterSizes_allPara,3,1,self.num_filters_allPara]\n",
    "        self.fullyConnectedLayerInput = 2100\n",
    "        \n",
    "        self.wordEmbedding = tf.Variable(tf.random_uniform([self.vocabularySize, self.wordEmbeddingDimension], -1.0, 1.0),name=\"wordEmbedding\")\n",
    "\n",
    "        self.paragraphList = []\n",
    "        for i in range(self.maxParagraph):\n",
    "            self.paragraphList.append(tf.placeholder(tf.int32,[self.paragraphLength],name=\"paragraphPlaceholder\"+str(i)))\n",
    "\n",
    "        self.target = tf.placeholder(tf.float32,[self.labels],name=\"target\")\n",
    "        \n",
    "        \n",
    "        graph()\n",
    "        self.session = tf.Session()\n",
    "        self.session.run(tf.global_variables_initializer())\n",
    "        \n",
    "    \n",
    "    def graph(self):\n",
    "        device_name='gpu'\n",
    "        with tf.device(device_name): \n",
    "            self.convOutput=convLayerCombineParagraph(self.paragraphList,self.filterSizes_paragraph,self.filterShapeOfAllPara,self.num_filters_parargaph,self.num_filters_allPara)\n",
    "            self.prediction=fullyConnectedLayer(self.convOutput,self.labels)\n",
    "            self.cross_entropy = -tf.reduce_sum(((self.target*tf.log(self.prediction + 1e-9)) + ((1-self.target) * tf.log(1 - self.prediction + 1e-9)) )  , name='xentropy' ) \n",
    "            self.cost = tf.reduce_mean(self.cross_entropy)\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(self.cost)\n",
    "    \n",
    "    \n",
    "    def getParagraphEmbedding(paragraphWords):\n",
    "        device_name='gpu'\n",
    "        with tf.device(device_name): \n",
    "            paraEmbedding=tf.nn.embedding_lookup(self.wordEmbedding,paragraphWords)\n",
    "    \n",
    "        return tf.expand_dims(tf.expand_dims(paraEmbedding, -1),0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def convLayeronParagraph(paragraphVector,filterSizes,num_input_channels,num_filters):\n",
    "    \n",
    "        pooled_outputs=[]\n",
    "        for filter_size in filterSizes:\n",
    "            shape = [filter_size,wordEmbeddingDimension,1,num_filters]\n",
    "\n",
    "            weights = tf.Variable(tf.truncated_normal(shape, stddev=0.1),name=\"paragraphConvLayerW_\"+str(filter_size))\n",
    "            bias= tf.Variable(tf.constant(0.1, shape=[num_filters]),name=\"paragraphConvLayerB_\"+str(filter_size))\n",
    "            conv = tf.nn.conv2d(\n",
    "                        paragraphVector,\n",
    "                        weights,\n",
    "                        strides=[1, 1, wordEmbeddingDimension, 1],\n",
    "                        padding=\"SAME\",\n",
    "                        name=\"conv\")\n",
    "\n",
    "            h = tf.nn.relu(tf.nn.bias_add(conv, bias), name=\"relu\")\n",
    "            pool_length=5\n",
    "            pooled = tf.nn.max_pool(\n",
    "                        h,\n",
    "                        ksize=[1, pool_length, 1, 1],\n",
    "                        strides=[1, pool_length, 1, 1],\n",
    "                        padding='SAME',\n",
    "                        name=\"pool\")\n",
    "            pooled_outputs.append(pooled)\n",
    "        return tf.reshape(tf.concat(pooled_outputs,axis=0),[1,-1])\n",
    "\n",
    "    \n",
    "    \n",
    "    def convLayerCombineParagraph(paragraphVectorList,filterSizes_paragraph,filterShapeOfAllPara,num_filters_parargaph,num_filters_allPara):\n",
    "    \n",
    "        paragraphCNNEmbedding=[]\n",
    "\n",
    "        for paragraph in paragraphVectorList:\n",
    "            paragraphVector = getParagraphEmbedding(paragraph)\n",
    "            cnnEmbedding = convLayeronParagraph(paragraphVector,filterSizes_paragraph,1,num_filters_parargaph)\n",
    "            paragraphCNNEmbedding.append(cnnEmbedding)\n",
    "\n",
    "        allParagraph=tf.expand_dims(tf.expand_dims(tf.concat(paragraphCNNEmbedding,axis=0),-1),0)\n",
    "\n",
    "        shape = filterShapeOfAllPara\n",
    "\n",
    "        weights= tf.Variable(tf.truncated_normal(shape, stddev=0.1),name=\"paragraphConvLayer2W_\"+str(filterShapeOfAllPara[0]))\n",
    "        bias= tf.Variable(tf.constant(0.1, shape=[num_filters_allPara]),name=\"paragraphConvLayer2B_\"+str(filterShapeOfAllPara[0]))\n",
    "\n",
    "        conv = tf.nn.conv2d(\n",
    "                        allParagraph,\n",
    "                        weights,\n",
    "                        strides=[1, 1, 1, 1],\n",
    "                        padding=\"SAME\",\n",
    "                        name=\"conv\")\n",
    "        h = tf.nn.relu(tf.nn.bias_add(conv, bias), name=\"relu\")\n",
    "        return tf.reshape(allParagraph,[1,-1])\n",
    "    \n",
    "    def fullyConnectedLayer(convOutput,labels):\n",
    "        shape = [fullyConnectedLayerInput,labels]\n",
    "        weights =tf.Variable(tf.truncated_normal(shape, stddev=0.1),name=\"FC_W\")\n",
    "        bias = tf.Variable(tf.constant(0.1, shape=[labels]),name=\"FC_Bias\")\n",
    "        layer = tf.nn.sigmoid(tf.matmul(convOutput, weights) + bias)\n",
    "        return layer\n",
    "    \n",
    "    def train(self,data):\n",
    "        feed_dict_input={}\n",
    "        feed_dict_input[self.target]=data[0]\n",
    "        for p in range(self.maxParagraph):\n",
    "            feed_dict_input[self.paragraphList[p]]= data[1][p]\n",
    "        self.session.run(self.optimizer,feed_dict=feed_dict_input)\n",
    "        return self.session.run(self.cost,feed_dict=feed_dict_input)\n",
    "\n",
    "    def predict(self,data):\n",
    "        feed_dict_input={}\n",
    "#         feed_dict_input[self.target]=data[0]\n",
    "        for p in range(self.maxParagraph):\n",
    "            feed_dict_input[self.paragraphList[p]]= data[1][p]\n",
    "        pred=self.session.run(self.prediction,feed_dict=feed_dict_input)\n",
    "        return pred\n",
    "          \n",
    "\n",
    "    def save(self,save_path):\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(self.session, save_path)\n",
    "\n",
    "\n",
    "    def load(self,save_path):\n",
    "        self.session = tf.Session()\n",
    "#         new_saver = tf.train.import_meta_graph(save_path)\n",
    "        new_saver = tf.train.Saver()\n",
    "        new_saver.restore(self.session, save_path)\n",
    "\n",
    "\n",
    "    def save_label_embeddings(self):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
